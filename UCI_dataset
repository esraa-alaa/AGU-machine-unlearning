import torch
import torch.nn as nn
import torch.optim as optim
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder

# Load and preprocess the UCI Adult dataset
def load_data():
    url = "https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data"
    columns = [
        "age", "workclass", "fnlwgt", "education", "education-num",
        "marital-status", "occupation", "relationship", "race", "sex",
        "capital-gain", "capital-loss", "hours-per-week", "native-country", "income"
    ]
    data = pd.read_csv(url, names=columns, sep=",\s*", engine="python")
    
    # Encode categorical features
    label_encoders = {}
    for column in data.select_dtypes(include="object").columns:
        if column != "income":
            le = LabelEncoder()
            data[column] = le.fit_transform(data[column])
            label_encoders[column] = le

    # Encode target
    data["income"] = data["income"].apply(lambda x: 1 if x == ">50K" else 0)

    # Split features and labels
    X = data.drop("income", axis=1)
    y = data["income"]

    # Train-test split
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    # Standardize numerical features
    scaler = StandardScaler()
    X_train = scaler.fit_transform(X_train)
    X_test = scaler.transform(X_test)

    return torch.tensor(X_train, dtype=torch.float32), torch.tensor(y_train.values, dtype=torch.long), \
           torch.tensor(X_test, dtype=torch.float32), torch.tensor(y_test.values, dtype=torch.long)

# Define a simple feedforward neural network
class TabularNN(nn.Module):
    def __init__(self, input_dim, hidden_dim, output_dim):
        super(TabularNN, self).__init__()
        self.fc1 = nn.Linear(input_dim, hidden_dim)
        self.fc2 = nn.Linear(hidden_dim, output_dim)

    def forward(self, x):
        x = torch.relu(self.fc1(x))
        x = self.fc2(x)
        return x

# AGU: Adaptive Gradient Unlearning Function
def adaptive_gradient_unlearning(model, dataset_to_forget, optimizer, criterion, eta=0.01, delta=1e-4, max_iters=100):
    model.train()
    sensitivity_scores = {name: torch.zeros_like(param) for name, param in model.named_parameters()}

    # Step 1: Compute sensitivity scores
    for data, target in dataset_to_forget:
        data, target = data.to(device), target.to(device)
        optimizer.zero_grad()
        output = model(data)
        loss = criterion(output, target)
        loss.backward()
        for name, param in model.named_parameters():
            if param.grad is not None:
                sensitivity_scores[name] += param.grad ** 2

    # Step 2: Normalize sensitivity scores
    max_score = max(score.max() for score in sensitivity_scores.values())
    for name in sensitivity_scores:
        sensitivity_scores[name] /= max_score

    # Step 3: Adaptive updates
    for _ in range(max_iters):
        converged = True
        for data, target in dataset_to_forget:
            data, target = data.to(device), target.to(device)
            optimizer.zero_grad()
            output = model(data)
            loss = criterion(output, target)
            loss.backward()
            for name, param in model.named_parameters():
                if param.grad is not None:
                    update = eta * sensitivity_scores[name] * param.grad
                    param.data -= update
                    if torch.abs(update).max() > delta:
                        converged = False
        if converged:
            break

# Load dataset
X_train, y_train, X_test, y_test = load_data()

# Prepare DataLoaders
train_dataset = torch.utils.data.TensorDataset(X_train, y_train)
test_dataset = torch.utils.data.TensorDataset(X_test, y_test)
train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)
test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)

# Define device, model, criterion, and optimizer
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
input_dim = X_train.shape[1]
hidden_dim = 64
output_dim = 2

model = TabularNN(input_dim, hidden_dim, output_dim).to(device)
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

# Train the model
def train(model, train_loader, optimizer, criterion, epochs=5):
    model.train()
    for epoch in range(epochs):
        total_loss = 0
        for data, target in train_loader:
            data, target = data.to(device), target.to(device)
            optimizer.zero_grad()
            output = model(data)
            loss = criterion(output, target)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch + 1}/{epochs}, Loss: {total_loss:.4f}")

# Test the model
def test(model, test_loader):
    model.eval()
    correct = 0
    total = 0
    with torch.no_grad():
        for data, target in test_loader:
            data, target = data.to(device), target.to(device)
            output = model(data)
            pred = output.argmax(dim=1)
            correct += (pred == target).sum().item()
            total += target.size(0)
    print(f"Accuracy: {100 * correct / total:.2f}%")

# Train and test before unlearning
train(model, train_loader, optimizer, criterion, epochs=5)
print("Before Unlearning:")
test(model, test_loader)

# Create dataset to unlearn (e.g., samples with income > 50K)
forget_indices = [i for i, target in enumerate(y_train) if target == 1]
forget_dataset = torch.utils.data.Subset(train_dataset, forget_indices)
forget_loader = torch.utils.data.DataLoader(forget_dataset, batch_size=64, shuffle=True)

# Apply AGU
adaptive_gradient_unlearning(model, forget_loader, optimizer, criterion)

# Test after unlearning
print("After Unlearning:")
test(model, test_loader)
